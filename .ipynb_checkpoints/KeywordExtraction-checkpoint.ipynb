{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78b4b833",
   "metadata": {},
   "source": [
    "Notebook'un olduğu klasörde şu dosyalar olmalıdır:\n",
    "data.csv = data,\n",
    "word2DocFreq.json = Her kelime için TF-IDF'teki document frequency,\n",
    "turkce_kelime_listesi.txt = Türkçe kelimelerin listesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a55f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT_COUNT = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79d009fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import string\n",
    "\n",
    "import zeyrek\n",
    "\n",
    "analyzer = zeyrek.MorphAnalyzer()\n",
    "\n",
    "def getLemmatizedWordList(sentence):\n",
    "    return [x[0].lemma for x in analyzer.analyze(sentence) if len(x) > 0 and x[0].lemma not in [*string.punctuation, 'Unk']]\n",
    "\n",
    "def getPOSTagList(sentence):\n",
    "    return [x[0].pos for x in analyzer.analyze(sentence) if len(x) > 0 and x[0].pos not in ['Punc', 'Unk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ed73dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import json\n",
    "\n",
    "TR_STOP = [\"ya da\", \"yada\", \"a\",\"acaba\",\"altı\",\"altmış\",\"ama\",\"ancak\",\"arada\",\"artık\",\"asla\",\"aslında\",\"aslında\",\"ayrıca\",\"az\",\"bana\",\"bazen\",\"bazı\",\"bazıları\",\"belki\",\"ben\",\"benden\",\"beni\",\"benim\",\"beri\",\"beş\",\"bile\",\"bilhassa\",\"bin\",\"bir\",\"biraz\",\"birçoğu\",\"birçok\",\"biri\",\"birisi\",\"birkaç\",\"birşey\",\"biz\",\"bizden\",\"bize\",\"bizi\",\"bizim\",\"böyle\",\"böylece\",\"bu\",\"buna\",\"bunda\",\"bundan\",\"bunlar\",\"bunları\",\"bunların\",\"bunu\",\"bunun\",\"burada\",\"bütün\",\"çoğu\",\"çoğunu\",\"çok\",\"çünkü\",\"da\",\"daha\",\"dahi\",\"dan\",\"de\",\"defa\",\"değil\",\"diğer\",\"diğeri\",\"diğerleri\",\"diye\",\"doksan\",\"dokuz\",\"dolayı\",\"dolayısıyla\",\"dört\",\"e\",\"edecek\",\"eden\",\"ederek\",\"edilecek\",\"ediliyor\",\"edilmesi\",\"ediyor\",\"eğer\",\"elbette\",\"elli\",\"en\",\"etmesi\",\"etti\",\"ettiği\",\"ettiğini\",\"fakat\",\"falan\",\"filan\",\"gene\",\"gereği\",\"gerek\",\"gibi\",\"göre\",\"hala\",\"halde\",\"halen\",\"hangi\",\"hangisi\",\"hani\",\"hatta\",\"hem\",\"henüz\",\"hep\",\"hepsi\",\"her\",\"herhangi\",\"herkes\",\"herkese\",\"herkesi\",\"herkesin\",\"hiç\",\"hiçbir\",\"hiçbiri\",\"i\",\"ı\",\"için\",\"içinde\",\"iki\",\"ile\",\"ilgili\",\"ise\",\"işte\",\"itibaren\",\"itibariyle\",\"kaç\",\"kadar\",\"karşın\",\"kendi\",\"kendilerine\",\"kendine\",\"kendini\",\"kendisi\",\"kendisine\",\"kendisini\",\"kez\",\"ki\",\"kim\",\"kime\",\"kimi\",\"kimin\",\"kimisi\",\"kimse\",\"kırk\",\"madem\",\"mi\",\"mı\",\"milyar\",\"milyon\",\"mu\",\"mü\",\"nasıl\",\"ne\",\"neden\",\"nedenle\",\"nerde\",\"nerede\",\"nereye\",\"neyse\",\"niçin\",\"nin\",\"nın\",\"niye\",\"nun\",\"nün\",\"o\",\"öbür\",\"olan\",\"olarak\",\"oldu\",\"olduğu\",\"olduğunu\",\"olduklarını\",\"olmadı\",\"olmadığı\",\"olmak\",\"olması\",\"olmayan\",\"olmaz\",\"olsa\",\"olsun\",\"olup\",\"olur\",\"olur\",\"olursa\",\"oluyor\",\"on\",\"ön\",\"ona\",\"önce\",\"ondan\",\"onlar\",\"onlara\",\"onlardan\",\"onları\",\"onların\",\"onu\",\"onun\",\"orada\",\"öte\",\"ötürü\",\"otuz\",\"öyle\",\"oysa\",\"pek\",\"rağmen\",\"sana\",\"sanki\",\"sanki\",\"şayet\",\"şekilde\",\"sekiz\",\"seksen\",\"sen\",\"senden\",\"seni\",\"senin\",\"şey\",\"şeyden\",\"şeye\",\"şeyi\",\"şeyler\",\"şimdi\",\"siz\",\"siz\",\"sizden\",\"sizden\",\"size\",\"sizi\",\"sizi\",\"sizin\",\"sizin\",\"sonra\",\"şöyle\",\"şu\",\"şuna\",\"şunları\",\"şunu\",\"ta\",\"tabii\",\"tam\",\"tamam\",\"tamamen\",\"tarafından\",\"trilyon\",\"tüm\",\"tümü\",\"u\",\"ü\",\"üç\",\"un\",\"ün\",\"üzere\",\"var\",\"vardı\",\"ve\",\"veya\",\"ya\",\"yani\",\"yapacak\",\"yapılan\",\"yapılması\",\"yapıyor\",\"yapmak\",\"yaptı\",\"yaptığı\",\"yaptığını\",\"yaptıkları\",\"ye\",\"yedi\",\"yerine\",\"yetmiş\",\"yi\",\"yı\",\"yine\",\"yirmi\",\"yoksa\",\"yu\",\"yüz\",\"zaten\",\"zira\"]\n",
    "TR_STOP = set(TR_STOP)\n",
    "\n",
    "DATASET_PATH = r\"data.csv\"\n",
    "dataDF = pd.read_csv(DATASET_PATH)\n",
    "    \n",
    "WORD_TO_DF_JSON_PATH = r\"word2DocFreq.json\"\n",
    "with open(WORD_TO_DF_JSON_PATH, 'r', encoding=\"utf8\") as word2FreqFile:\n",
    "    WORD_TO_DF = json.load(word2FreqFile)\n",
    "\n",
    "VOCABULARY_PATH = r\"turkce_kelime_listesi.txt\"\n",
    "with open(VOCABULARY_PATH, 'r', encoding=\"utf8\") as vocabFile:\n",
    "    VOCABULARY = json.load(vocabFile, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41a565d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rake-nltk in c:\\users\\furkan\\anaconda3\\lib\\site-packages (1.0.6)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in c:\\users\\furkan\\anaconda3\\lib\\site-packages (from rake-nltk) (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\furkan\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\furkan\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\furkan\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\furkan\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\furkan\\anaconda3\\lib\\site-packages (from click->nltk<4.0.0,>=3.6.2->rake-nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "%pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9167039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ödenek', 52.18882790656838), ('gelir', 14.172133332659614), ('kurul', 13.29051335893929), ('hibe', 12.994691088312916), ('altyapı', 9.637254967214696), ('inşa', 8.87324368123922), ('kurum', 8.133166475355393), ('fonksiyonel', 8.089105578844608), ('kuruluş', 7.799895855642738), ('ikinci', 7.706870130578963)]\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "import re\n",
    "import math\n",
    "\n",
    "TEXT = dataDF.iloc[0][\"data_text\"]\n",
    "LEMMATIZED_TEXT = ' '.join(getLemmatizedWordList(TEXT))\n",
    "\n",
    "rake = Rake(language=\"turkish\", max_length=6)\n",
    "\n",
    "rake.extract_keywords_from_text(TEXT)\n",
    "\n",
    "keywordsWithScores = list(set(rake.get_ranked_phrases_with_scores()))\n",
    "\n",
    "finalKeywordsWithScores = []\n",
    "for kwIndex in range(len(keywordsWithScores)):\n",
    "    score, kw = keywordsWithScores[kwIndex]\n",
    "    kw = kw.lower()\n",
    "    if len(kw) >= 2 and not kw.isdigit():\n",
    "        words = kw.split(' ')\n",
    "        docFreq = 1\n",
    "        OOVCount = 0\n",
    "        for word in words:\n",
    "            if not word in VOCABULARY:\n",
    "                OOVCount += 1\n",
    "            docFreq *= WORD_TO_DF.get(word, 1)\n",
    "        docFreq /= len(words)\n",
    "        \n",
    "        # Out of vocabulary (OOV) filtrelemesi:\n",
    "        if OOVCount / len(words) >= 0.6:\n",
    "            continue\n",
    "            \n",
    "        lemmatizedWords = getLemmatizedWordList(kw)\n",
    "        \n",
    "        # TF-IDF etkisinin çarpılması:\n",
    "        score *= len(re.findall(fr\"\\b{' '.join(lemmatizedWords)}\\b\", LEMMATIZED_TEXT)) * math.log(DOCUMENT_COUNT / docFreq, 10)\n",
    "        \n",
    "        finalKeywordsWithScores.append((kw, score))\n",
    "        \n",
    "print(sorted(finalKeywordsWithScores, reverse=True, key=lambda elem: elem[1])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf6f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
